---
title: "Sampling Distributions"
format:
  revealjs:
    author: "STAT 20: Introduction to Probability and Statistics"
    height: 900
    width: 1600
    theme: ../../assets/slides.scss
    multiplex: false
    transition: fade
    slide-number: c
    incremental: false
    center: false
    menu: false
    highlight-style: github
    progress: false
    code-overflow: wrap
    title-slide-attributes:
      data-background-image: ../../assets/stat20-hex-bg.png
      data-background-size: contain
---

## Agenda

1. Concept Questions
2. PS: Sampling Distributions
3. Lab


##

```{r}
countdown::countdown(1, bottom = 0)
```
 
\
 
:::{.poll}
The top plots are population distributions; the bottom two are sampling distributions of the means from many samples of size 200. Match numbers to letters.
:::

:::{.notes}
Correct answer: It depends on the sampling process.

These sampling distributions were actually made from taking samples of size 200 with replacement from populations of size 100. Most students will assume this when they first answer and choose 1-B, 2-A. This is a good opportunity to cue them to think very carefully about exactly how it is worded, then give them time to discuss and revote.
:::

```{r}
#| fig-width: 8
#| fig-height: 5
#| fig-align: center
library(tidyverse)
set.seed(123123)
family_pop1 <- rep(c(1,2,3,4), times = c(20,40,25,15)) 
family_pop2 <- rep(c(1,2,3,4), times = c(15,20,35,30))

pop_plot1 <- ggplot(data.frame(family_pop1), aes(x=family_pop1)) +
  geom_bar(fill = "gray55", width = 0.98) + 
  xlab("") + 
  annotate("text", x=3.8, y = 35, label="(1)", color = "black", size=5) +
  theme_gray(base_size = 16)

pop_plot2 <- ggplot(data.frame(family_pop2), aes(x=family_pop2)) +
  geom_bar(fill = "gray55", width = 0.98) + 
  xlab("") + 
  annotate("text", x=1, y = 30, label="(2)", color = "black", size=5) +
  theme_gray(base_size = 16)

family_sample1 <- replicate(500, 
                        mean(sample(family_pop1, 200, replace = TRUE)))

sample_plot1 <- ggplot(data.frame(family_sample1), aes(x=family_sample1)) +
  geom_histogram(fill = "gray", color = "black",
                 bins = 25) + xlab("") +
  annotate("text", x=2.2, y = 42, label="(B)", color = "black", size=5) +
  theme_gray(base_size = 16)

family_sample2 <- replicate(500, 
                            mean(sample(family_pop2, 200, replace = TRUE)))

sample_plot2 <- ggplot(data.frame(family_sample2), aes(x=family_sample2)) +
  geom_histogram(fill = "gray", color = "black",
                 bins = 25) + xlab("") +
  annotate("text", x=3, y = 60, label="(A)", color = "black", size=5) +
  theme_gray(base_size = 16)

library(patchwork)

(pop_plot1 + pop_plot2) / (sample_plot2 + sample_plot1)
```

##

Say we want to estimate the size of an average class at Berkeley. 

:::{.poll}
Should we survey the students, and ask them how large their classes are? Should we ask the administration?  Does it matter?
:::

```{r}
countdown::countdown(1, bottom = 0)
```

::: {.notes}
This one you may want to send straight to "discuss with your group".

This is a good question to debrief with careful boardwork. You can go quite deep on it, so decide beforehand how far you'd like to go.

One way to start the debrief is to make a table of Pros and Cons for both the Administration and the Student Survey, then ask students for help filling it in. Things that might come up include sources of variability (small sample variability in the survey), non-response bias in the survey, and possibly selection bias in the survey (which could take several forms).

You can also debrief by sketching data frames. For the administrative data, draw a sketch of the data frame they have access to, where the unit is a class, and one of the columns records the class size. Then draw a sketch of the student survey data frame, where the unit is a student in a particular class, with a column that records the class size. If you summarize the class size column with the mean in the first dataframe and n = N, then you've just calculated the parameter - it's a summary task, no generalization necessary.

If you take the mean of class size in the student survey data set, you'll get a *much* bigger number, because you'll be over-sampling students from the very large classes. This can be thought of as selection bias, leading to an overestimate of the parameter.

One wrinkle that you could end with: which of those two averages is actually better for understanding the effect of large class sizes? The first one is a property of classes. That might be useful for thinking through things like the size of classrooms on campus. The second average is a property of students. In a way, it better captures the student experience of being in large vs small classes.

This is going very far afield, but there's a similar phenomenon when measuring population density of cities. If it's measured as people / sq mile, that gives us a sense of how each sq mile of land feels. You could also measure it using the average number of people that you run into in a day per person. This gives a sense of how crowded things are.

These two measures diverge if you imagine a city on 2 square miles with a population of 100,000 people split evenly between those two squares. Then imagine a second city also on 2 sq miles, but 99,999 live in one sq mile and just 1 person lives in the other square mile. By the first metric, they have the same density, but the second city will feel much more density to its residents.
:::


##

#### Scenario 1: Calling on the front row

```{r}
library(tidyverse)
pop_eager <- data.frame(year = factor(rep(c(1, 2, 3, 4), 
                                   times = c(245, 210, 47, 25))),
                        eagerness = rep(c(10, 6, 3, 1), 
                                        times = c(245, 210, 47, 25)))
set.seed(34)
pop_eager <- pop_eager %>%
  slice_sample(n = nrow(pop_eager)) 

library(infer)
samp_1 <- pop_eager %>%
  slice_sample(n = 18,
                   replace = FALSE,
                   weight_by = eagerness) 

many_samps <- samp_1 %>%
  mutate(replicate = 1)

set.seed(40211)

for (i in 2:500) {
  many_samps <- pop_eager %>%
    slice_sample(n = 18,
                 replace = FALSE,
                 weight_by = eagerness) %>%
    mutate(replicate = i ) %>%
    bind_rows(many_samps)
}

p1 <- many_samps %>%
  filter(replicate == 1) %>%
  ggplot(aes(x = year)) + 
  geom_bar() +
  labs(title = "Sample 1")

p2 <- many_samps %>%
  filter(replicate == 2) %>%
  ggplot(aes(x = year)) + 
  geom_bar() +
  labs(title = "Sample 2")

p3 <- many_samps %>%
  filter(replicate == 3) %>%
  ggplot(aes(x = year)) + 
  geom_bar() +
  labs(title = "Sample 3")

many_xbars <- many_samps %>%
  group_by(replicate) %>%
  summarize(xbar = mean(as.numeric(year)))

p4 <- many_xbars %>%
  ggplot(aes(x = xbar)) +
  geom_bar(fill = "purple") +
  geom_vline(xintercept = mean(as.numeric(pop_eager$year)),
             col = "blue", lwd = 1.5) +
  lims(x = c(0, 4)) +
  labs(title = "Sampling Distribution")

library(patchwork)

p_patched <- (p1 + p2 + p3) / p4
p_patched
```

::: notes
This is the example from the notes, where the prof just takes a sample of size n = 18 from the first row. 1st year students are 10 times more likely to be drawn than 4th year students. The result is that most of the sample means are below the true population parameter (the blue vertical line).
:::

##

```{r}
#| fig-height: 2
#| fig-width: 6
#| fig-align: center

p4 +
  labs(title = "Sampling Distribution from calling on the first row")
```

:::poll
How would the sampling distribution **change** if instead of calling on the front row, the Prof. put all 527 names on tickets in a box, mixed them up, then drew 18 names without replacement?
:::

::: notes
This describes a simple random sample, the sampling distribution will move up to be centered around the parameter.

A few follow up questions if you'd like:

1. What would happen if in the SRS we called on 8 instead of 18? Answer: the sampling distribution would still be centered about the parameter, but the standard deviation would increase.

Takehome: sampling variability for an average increases or decreases with changing sample size according to 1/sqrt(n).

2. Returning to the "calling on the front row" sampling method and plot: what would happen if, by the end of the semester, 90% of students sit in the same seat every class period? Answer: in that case there would be very little variability from one day / sample to the next and the SD of the sampling distribution would decrease dramatically.

Takehome: if there is little / no variability in the sampling process, there really isn't much of a sampling distribution. It's more like a constant and your only concern is bias.
:::

```{r}
countdown::countdown(1, bottom = 0)
```

##

#### Scenario 2: Drawing names from a box

```{r}
pop_equal <- pop_eager %>%
  mutate(eagerness = 1)

samp_1 <- pop_equal %>%
  slice_sample(n = 18,
                   replace = FALSE,
                   weight_by = eagerness)

many_samps <- samp_1 %>%
  mutate(replicate = 1)

for (i in 2:500) {
  many_samps <- pop_equal %>%
    slice_sample(n = 18,
                 replace = FALSE,
                 weight_by = eagerness) %>%
    mutate(replicate = i ) %>%
    bind_rows(many_samps)
}

p1 <- many_samps %>%
  filter(replicate == 1) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 1")

p2 <- many_samps %>%
  filter(replicate == 2) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 2")

p3 <- many_samps %>%
  filter(replicate == 3) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 3")

many_xbars <- many_samps %>%
  group_by(replicate) %>%
  summarize(xbar = mean(as.numeric(year)))

p4 <- many_xbars %>%
  ggplot(aes(x = xbar)) +
  geom_bar(fill = "purple") +
  geom_vline(xintercept = mean(as.numeric(pop_eager$year)),
             col = "blue", lwd = 1.5) +
  lims(x = c(0, 4)) +
  labs(title = "Sampling Distribution")

(p1 + p2 + p3) / p4
```


# PS: Sampling Distributions

```{r}
countdown::countdown(20, bottom = 0)
```


# Lab

```{r}
countdown::countdown(20, bottom = 0)
```