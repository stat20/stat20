---
title: "Hypothesis Tests II"
format: stat20slides-revealjs
execute: 
  echo: false
---

## Agenda

-   Announcements
-   Concept Questions
-   *Break*
-   PS 14: *Hypothesis Tests II*

## Announcements

-   RQ: *Wrong By Design* due Wed/Thu night at 11:59pm

. . . 

-   Quiz 3 is in the first half of *class* on Thursday/Friday.

. . . 

-   *Problem Set 14* is due the Tuesday after break. 

# Concept Questions

##

Which pair of plots would have the *greatest* chi-squared distance between them? (consider one of them the "observed" and the other the "expected")

```{r}
library(ggplot2)
df <- data.frame(x = c(rep(c("red", "green", "blue"), 
                           times = c(3, 2, 7)),
                       rep(c("red", "green", "blue"), 
                           times = c(5, 4, 3)),
                       rep(c("red", "green", "blue"), 
                           times = c(3, 4, 5)),
                       rep(c("red", "green", "blue"), 
                           times = c(1, 10, 1)),
                       rep(c("red", "green", "blue"), 
                           times = c(4, 4, 4)),
                       rep(c("red", "green", "blue"), 
                           times = c(10, 1, 1))),
                 lab = rep(LETTERS[1:6], each = 12))

ggplot(df, aes(x = x)) +
  geom_bar() +
  facet_wrap(vars(lab)) +
  theme_bw(base_size = 14)
```

```{r}
countdown::countdown(1)
```

:::notes
This question recalls the introduction of a new summary statistic in the notes: the chi-squared. It is used to measure the distance between two distributions of categorical variables. The pair with the highest statistic is D and F. The important mathematical intuition to have here is that the statistic adds together every squared normalized difference, so one very large difference can inflate the statistic.
:::

## Chi-squareds Compared

:::columns
:::{.column width="50%"}

```{r}
library(dplyr)
df |>
  filter(lab %in% c("D", "F")) |>
  ggplot(aes(x = x)) +
  geom_bar() +
  facet_wrap(vars(lab)) +
  theme_bw(base_size = 14)
```

```{r}
#| warning: false
#| eval: false
library(infer)
# D vs F
df |>
  filter(lab %in% c("D")) |>
  chisq_stat(response = x,
             p = c("blue" = 1/12,
                   "green" = 1/12,
                   "red" = 10/12))
```

$$
\frac{(1-1)^2}{1} + \frac{(10 - 1)^2}{1} + \frac{(1 - 10)^2}{10} \\
0 + 81 + \frac{81}{10}  = 89.1
$$

:::
:::{.column width="50%" .fragment}
```{r}
df |>
  filter(lab %in% c("B", "C")) |>
  ggplot(aes(x = x)) +
  geom_bar() +
  facet_wrap(vars(lab)) +
  theme_bw(base_size = 14)
```

```{r}
#| eval: false
# B vs C
df |>
  filter(lab %in% c("B")) |>
  chisq_stat(response = x,
             p = c("blue" = 5/12,
                   "green" = 4/12,
                   "red" = 3/12))
```

$$
\frac{(3-5)^2}{5} + \frac{(4-4)^2}{4} + \frac{(5-3)^2}{3} \\
\frac{4}{5} + 0 + \frac{4}{3} = 2.13
$$

:::
:::


## An In-class Experiment

In order to demonstrate how to conduct a hypothesis test through simulation, we will be collecting data from this class using a poll.

\
\

You will have only 15 seconds to answer the following multiple choice question, so please get ready at `pollev.com`...

::: notes
This sets up a discussion of how to set up a hypothesis test that p = .5.

This is based on a series of experiments that show a link between sounds and shapes in people's minds - sharper shapes correspond to sharper sounds (k, t) and rounder shapes to rounder sounds (m, b). Read more about it here: https://en.wikipedia.org/wiki/Bouba/kiki_effect.

You conduct the experiment on the students using a poll question, then you calculate a proportion, then entertain the notion that linking names to shapes is meaningless, so people were choosing randomly, then use that to motivate the hypothesis test that p = .5.
:::

## 

![](images/booba-kiki.svg){fig-align="center"}

::: poll
The two shapes above have simple first names:

- Booba
- Kiki

Which of the two names belongs to the shape on the **left**?
:::

```{r}
countdown::countdown(minutes = 0, seconds = 15)
```

::: notes
This poll everywhere question is set up to record the counts of each category and display the total number of responses in the upper right. This allows you to discuss the results either in terms of a binomial or in terms of a proportion.
:::

## Steps of a Hypothesis Test

1. Assert a model for how the data was generated (the null hypothesis)
2. Select a test statistic that bears on that null hypothesis (a mean, a proportion, a difference in means, a difference in proportions, etc).
3. Approximate the sampling distribution of that statistic under the null hypothesis (aka the null distribution)
4. Assess the degree of consistency between that distribution and the test statistic that was actually observed (either visually or by calculating a p-value)

## 1. The Null Hypothesis

- Let $p_k$ be the probability that a person selects Kiki for the shape on the left.
- Let $\hat{p}_k$ be the sample proportion of people that selected Kiki for the shape on the left.

::: poll
What is a statement of the null hypothesis that corresponds to the notion the link between names and shapes is arbitrary?
:::

```{r}
countdown::countdown(1)
```

## 2. Select a test statistic

$$\hat{p}_k = \frac{\textrm{Number who chose "Kiki"}}{\textrm{Total number of people}}$$

. . .

\

Note: you could also simply $n_k$, the number of people who chose "Kiki".

::: notes
A follow-up question to ask: "For our class, what would we expect this number to be if $p_k = .5$?"

It should be half the number of students who responded to the poll.
:::


## 3. Approximate the null distribution

Our technique: simulate data from a world in which the null is true, then calculate the test statistic on the simulated data.

::: poll
Which simulation method(s) align with the null hypothesis and our data collection process?
:::

```{r}
countdown::countdown(1)
```

::: notes
A, C, and E all work.
:::


## Simulating the null using `infer`

```{r}
#| echo: true
#| eval: false

library(tidyverse)
library(infer)

# update these based on the poll
n_k <- 40
n_b <- 20

shapes <- data.frame(name = c(rep("Kiki", n_k),
                              rep("Booba", n_b)))

shapes |>
  specify(response = name,
          success = "Kiki") |>
  hypothesize(null = "point", p = .5) |>
  generate(reps = 1, type = "draw") |>
  calculate(stat = "prop")
```

::: notes
1. have students open laptops and an R script to code along.
2. copy and paste the code cell from the slides into RStudio
3. replace n_k and n_b with the values from your poll.
4. "break the pipe" to show what happens at every stage.
5. run several pipelines with reps = 1 to show it changing.
6. set reps to 500 to show the full collection of p-hats.
:::

## 4. Assess the consistency of the data and the null

```{r}
#| echo: true
#| eval: false

null <- shapes |>
  specify(response = name,
          success = "Kiki") |>
  hypothesize(null = "point", p = .5) |>
  generate(reps = 500, type = "draw") |>
  calculate(stat = "prop")

obs_p_hat <- shapes |>
  specify(response = name,
          success = "Kiki") |>
  # hypothesize(null = "point", p = .5) |>
  # generate(reps = 500, type = "simulate") |>
  calculate(stat = "prop")
```


## 4. Assess the consistency of the data and the null

```{r}
#| echo: true
#| eval: false
null |>
  visualise() +
  shade_pvalue(obs_p_hat, direction = "both")

null |>
  get_p_value(obs_p_hat, direction = "both")
```



## The p-value

::: poll
What is the proper interpretation of this p-value?
:::

```{r}
countdown::countdown(1)
```

## The Bouba / Kiki Effect

<iframe src="https://en.wikipedia.org/wiki/Bouba/kiki_effect" height=600 width=1500>
</iframe>

# *Break*

```{r}
countdown::countdown(5)
```

# Problem Set 14: *Hypothesis Testing II*

```{r}
countdown::countdown(50)
```
