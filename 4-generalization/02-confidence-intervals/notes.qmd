---
title: "Confidence Intervals"
subtitle: "Quantifying the random variability of a statistic."
toc-depth: 4
format:
  html: default
  pdf:
    echo: false
---

```{r}
#| echo: false
#| message: false
#| warning: false

library(tidyverse)
library(stat20data)
library(infer)
library(palmerpenguins)
library(patchwork)
```

[T]{.dropcap}he process of generalizing from a statistic of a sample to a parameter of a population is known as *statistical inference*. The parameter of interest could be a mean, median, proportion, correlation coefficient, the coefficient of a linear model . . . the list goes on. In the scenario that unfolded in Pimentel Hall, the parameter was the mean year of the 527 students in the class. The process of estimating that parameter by calculating the sample mean of a random subset of students induces a sampling distribution.

This sampling distribution captures the two sources of error that creep in while generalizing. The horizontal offset from true population parameter to the mean of the sampling distribution represents the bias. The spread of the sampling distribution represents the random variability.

In these lecture notes you'll learn how to quantify random variability using two common tools.

**Standard Error (SE)**
: The standard deviation of the sampling distribution of a statistic.

**Confidence Interval**
: An interval of two values calculated from a sample that represents a plausible range for the unknown parameter.

To focus on the random variability, let's imagine a different scenario unfolding in Pimentel Hall, one in which we will not need to worry about bias.

## Scenario 2: Drawing names from a box

Instead of calling on students who happen to sit in the front row, the professor decides to take a more systematic approach. Before class, he makes a box with 527 tickets, each one showing the name of a different student in the class. During class, he randomly draws out 18 tickets without replacement, calls on those students, then writes their years down on the blackboard.

Instead of focusing on the average age of the 527 students in the class, the professor this time is interested in a different parameter: the proportion of students who are in their first year.

The professor writes the years of the first three students on the board next to a variable $x$, which takes a value of 1 for first year students and 0 otherwise.

| Year |  x  |
|:----:|:---:|
|  3   |  0  |
|  1   |  1  |
|  2   |  0  |

Because the values in the column `x` are a result of a random sample process, each one can be thought of as a realization of a random variable. Let $X_i$ be 1 if the $i$^th^ randomly selected student is a first year and 0 otherwise.

$$
X_i \sim Bernoulli(p)
$$

where $p$ is the (unknown!) proportion of students in the class that are first years - the parameter of interest.

This is helpful: it casts the random part of the process in precise probability language that we're familiar with. It also makes clear the central challenge of statistical inference: how do we estimate an unknown parameter using only observations of random variables? And further: how can we convey our own uncertainty in the estimate due to the randomness?

### From Point to Interval Estimates

Once the professor has the full sample of 18 observations on the board, the most natural estimate of the proportion of first years in the whole class is the sample proportion, $\hat{p}$ of first years among those 18 observations. This 

If we consider each observation to be a random variable, though, that means $\hat{p}$ is itself an observation of a random variable. Let $\hat{P}$ be the proportion of first year students in a sample of size $n$. Let's rewrite it in terms of random variables that we're more familiar with.

$$
\begin{eqnarray}
\hat{P} &= \frac{1}{n}\left( X_1 + X_2 + \ldots + X_n \right) \\
&= \frac{1}{n}\left( S_n \right) 
\end{eqnarray}
$$

What distribution does $S_n$ follow? The professor has drawn each ticket out *without replacement*, so this is best 

```{r}
#| echo: false
#| eval: false
pop_equal <- pop_eager %>%
  mutate(eagerness = 1)

samp_1 <- pop_equal %>%
  slice_sample(n = 18,
                   replace = FALSE,
                   weight_by = eagerness)

many_samps <- samp_1 %>%
  mutate(replicate = 1)

for (i in 2:500) {
  many_samps <- pop_equal %>%
    slice_sample(n = 18,
                 replace = FALSE,
                 weight_by = eagerness) %>%
    mutate(replicate = i ) %>%
    bind_rows(many_samps)
}

p1 <- many_samps %>%
  filter(replicate == 1) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 1")

p2 <- many_samps %>%
  filter(replicate == 2) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 2")

p3 <- many_samps %>%
  filter(replicate == 3) %>%
  ggplot(aes(x = year)) +
  geom_bar() +
  labs(title = "Sample 3")

many_xbars <- many_samps %>%
  group_by(replicate) %>%
  summarize(xbar = mean(as.numeric(year)))

p4 <- many_xbars %>%
  ggplot(aes(x = xbar)) +
  geom_bar(fill = "purple") +
  geom_vline(xintercept = mean(as.numeric(pop_eager$year)),
             col = "blue", lwd = 1.5) +
  lims(x = c(0, 4)) +
  labs(title = "Sampling Distribution")

(p1 + p2 + p3) / p4
```

