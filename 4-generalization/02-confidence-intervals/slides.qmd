---
title: "Confidence Intervals"
format: stat20slides-revealjs
---

## Agenda

- Concept Questions
- Lab 5

# Concept Questions

## 

You embark on a mission to estimate a population mean using a simple random sample of $n$ observations.

:::poll
What sample size would you need to increase the precision of your estimate by approximately 3x compared to the original sample?
:::

:::notes
A. n + 3
B. 3n
D. n + 6
C. 6n
D. 9n

This assesses the 1/sqrt(n) relationship between the SE of a mean and the SD of the population. This relationship is worth reviewing. It's also a good time to underline the definition of SE from the notes, and its link to our notion of "precision".
:::

```{r}
countdown::countdown(1)
```



##

```{r}
#| echo: true
#| fig-align: center
library(tidyverse)
library(stat20data)

set.seed(5)
flights %>%
  slice_sample(n = 30) %>%
  summarize(xbar = mean(air_time),
            sx = sd(air_time),
            n = n())
```

:::poll
What is an approximate 95% confidence interval for the mean air time in `flights` using the normal curve?
:::

```{r}
countdown::countdown(1, top = 0)
```


:::notes
A. 30 +/- 1.96 * 81.5 * sqrt(118)
B. 118 +/- 1.68 * 81.5 / sqrt(30)
C. 118 +/- 1.96 * 81.5 / sqrt(30)
D. 30 +/- 1.68 * 118 / sqrt(81.5)

Answer: C. This is a simple application of the formula for a CI based on the normal approximation.

This is a good question to kick off a discussion of the interpretation of confidence intervals by recreating the figure from the notes of many CIs from many samples, 5% of which cover the parameter. You can sketch the empty plot on the board, add the CI from this question, then rerun the code in R (with no set seed), to get another point estimate and another interval... and so on until you demonstrate that ~95% of such intervals should contain the parameter.

Note that you can find the parameter by just emitting the `slice_sample()` line of code.
:::


##

An economist aims to estimate the average weekly cost of groceries per household in two cites: **Oakland**, CA (population ~400,000) and **Fremont**, CA (population ~200,000). Both of these populations of households are presumed to have a similar standard deviation of weekly grocery costs. The economist takes a simple random sample (without replacement) of 100 households from each city, records their costs, and computes a 95% confidence interval for the average weekly cost.

:::poll
Approximately how much wider would Oakland's confidence interval be than Fremont's?
:::

:::notes
A. 1.5 times as wide
B. 2 times as wide
C. 3 times as wide
D. 4 times as wide
E. The same width

It's more or less E here since N is so large.
:::

```{r}
countdown::countdown(1)
```

##

An economist aims to estimate the average weekly cost of groceries per household in two cites: **Grimes**, CA (population ~400) and **Tranquility**, CA (population ~800). Both of these populations of households are presumed to have a similar standard deviation of weekly grocery costs. The demographer takes a simple random sample (without replacement) of 100 households from each city, records their costs, and computes a 95% confidence interval for the average weekly cost.

:::poll
Approximately how much wider would Tranquility's confidence interval be than Grimes's?
:::

:::notes
A. Half as wide
B. Roughly 10% less than Grimes
C. The same width
D. Roughly 10% more than Grimes
E. Twice as wide

Sampling without replacement in a setting where n is not significantly smaller than N will end up showing less variability in statistics than when N is huge. The effect is slight, so you can eyeball that the answer should be D.

You can get the precise answer by calculating the finite population correction factor for each one: \sqrt((N - n)/(N-1)). This is in a footnotes to the notes but is good for them to be aware of - that we can't always just use SD(pop)/sqrt(n).
:::

```{r}
countdown::countdown(2)
```

##

```{r}
#| echo: false
#| fig-align: center

library(tidyverse)
library(patchwork)

load("fs_scores.rda")

set.seed(103122)
samp_scores <- sample(fs_scores, 100)

set.seed(10312022)
samp_means <- replicate(100000, mean(sample(fs_scores, 100)))

pop_dist <- ggplot(as.data.frame(fs_scores), aes(x=fs_scores, y=..density..)) + 
      geom_histogram(breaks=seq(47.5, 100.5, by = 1), 
                 color="black", fill="gray") + 
      xlab("Food Safety Scores") +
      ylab("Proportion") +
      ggtitle("Population Distribution")

emp_dist <- ggplot(as.data.frame(samp_scores), aes(x=samp_scores, y=..density..)) + 
      geom_histogram(breaks=seq(47.5, 100.5, by = 1), 
                 color="black", fill="gray") + 
      xlab("Food Safety Scores") +
      ylab("Proportion") +
      ggtitle("Empirical Distribution")

sampling_dist <- ggplot(as.data.frame(samp_means), 
                        aes(x=samp_means, y=..density..)) + 
      geom_histogram(bins = 45, 
                 color="black", fill="gray") + 
      xlab("Average Food Safety Scores for a SRS of 100") +
      ylab("Proportion") +
      ggtitle("Sampling Distribution")

pop_dist + emp_dist + sampling_dist
```

:::poll
What will happen to the shape of the **empirical distribution** as we increase $n$?
:::

```{r}
countdown::countdown(1, top = 0)
```


:::notes
A. The standard deviation will decrease.
B. The standard deviation will increase.
C. The mean will increase
D. It will more closely resemble the population dist.
E. It will more closely resemble the sampling dist.

The answer is D.

This plot and example are from the notes. It is probably good to remind them than in any practical setting you only get to see the empirical distribution. Here we have the full population and we're simulating drawing many samples to get a sense of what that sampling distribution should look like.
:::

##

```{r}
#| echo: false
#| fig-align: center

library(tidyverse)
library(patchwork)

load(url("https://www.dropbox.com/s/nbgw1uzj5ccwce2/fs_scores.rda?dl=1"))

set.seed(103122)
samp_scores <- sample(fs_scores, 100)

set.seed(10312022)
samp_means <- replicate(100000, mean(sample(fs_scores, 100)))

pop_dist <- ggplot(as.data.frame(fs_scores), aes(x=fs_scores, y=..density..)) + 
      geom_histogram(breaks=seq(47.5, 100.5, by = 1), 
                 color="black", fill="gray") + 
      xlab("Food Safety Scores") +
      ylab("Proportion") +
      ggtitle("Population Distribution")

emp_dist <- ggplot(as.data.frame(samp_scores), aes(x=samp_scores, y=..density..)) + 
      geom_histogram(breaks=seq(47.5, 100.5, by = 1), 
                 color="black", fill="gray") + 
      xlab("Food Safety Scores") +
      ylab("Proportion") +
      ggtitle("Empirical Distribution")

sampling_dist <- ggplot(as.data.frame(samp_means), 
                        aes(x=samp_means, y=..density..)) + 
      geom_histogram(bins = 45, 
                 color="black", fill="gray") + 
      xlab("Average Food Safety Scores for a SRS of 100") +
      ylab("Proportion") +
      ggtitle("Sampling Distribution")

pop_dist + emp_dist + sampling_dist
```

:::poll
What will happen to the shape of the **sampling distribution** as we increase $n$?
:::

```{r}
countdown::countdown(1, top = 0)
```


:::notes
A. The standard deviation will decrease
B. The standard deviation will increase
C. The mean will increase
D. It will more closely resemble the population dist.
E. It will more closely resemble the sampling dist.

The answer is A but note here the SD of the sampling dist is called the SE.
:::

# Lab: People's Park

```{r}
countdown::countdown(25)
```

