---
title: "Lab 6: Breast cancer diagnosis"
date: "10/14/22"
image: images/benign_vs_malignant.png
---

In this lab you will train and evaluate a classification algorithm to determine whether or not a [fine needle aspiration biopsy](https://en.wikipedia.org/wiki/Fine-needle_aspiration) is cancerous (malignant) or non-cancerous (benign). The data were downloaded from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29) and lightly processed. There are 568 observations in this data set and each sample is one biopsy.
Each biopsy has 30 features summarizing the nuclear morphology of the cells in the biopsy.
See the lecture slides for some additional explanation.

The purpose of this lab is to practice using the code from the [classification case study notes](https://www.stat20.org/3-prediction/16-classification-case-study/notes.html). **Much of part 2 can be answered by copying/pasting/tweaking the code from these notes.**

The variables that end in `_se` are cell standard deviations (they are using the term *standard error*).

## Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, message=FALSE, warn=FALSE}
library(tidyverse)

# you may need to install the caret package
# which you can accomplish by uncommenting the following line
# you only need to install a package ONCE i.e. you can run this line once then never again
# install.packages('caret')

library(caret)

# load data, do some pre-processing
cells <- read_csv('https://raw.githubusercontent.com/idc9/course-materials/main/3-prediction/labs/brca_fna_data.csv')

# make diagnosis a factor -- this is required to make the code below work!
cells <- cells %>% 
    mutate(diagnosis=as.factor(diagnosis))

cells
```

The diagnosis is in the column named `diagnosis`; each other column should be used to predict the diagnosis.

## Part 1: Understanding and Exploring the Data

1. How many classes are in diagnosis?

2. Use a box plot to compare the `radius_mean` for benign vs. malignant biopsies. What is the takeaway from this plot?

3.  Repeat the previous question for another variable of your choosing. What is the interpretation?

4.  Make a plot that examines the association between `radius_mean` and `area_mean`. Calculate the correlation between these two variables. Is there a strong association between these two variables? Does this make sense?

5.  Make a single plot that examines the association between `radius_mean` and `radius_se` separately for each diagnosis. Hint: `aes()` should have three arguments. Calculate the correlation between these two variables for each diagnosis.

    Give an interpretation of these results. In particular comment on

    - Is the relationship between `radius_mean` and `radius_se` different for benign biopsies vs. malignant biopsies?

    - If so, can you give an explanation for this difference?


# Part 2: Classification with K-nearest-neighbors

6.  Split the full cells data set into an 80/20 train/test set split. Name the training data frame `train_df` and the test data frame `test_df`.

    Make sure you use the seed in the code chunk shown below.

    ```{r message=FALSE}
    set.seed(1234)

    # start writing your code here
    # train_indices <- createDataPartition
    ```

7.  Fit a KNN model with K=1 to the training data. Evaluate the training accuracy and test accuracy of this model. Hint: using the `knn3` function from the `caret` package as in the notes.

8.  Repeat the previous question with K=20.

9.  Standardize the training and test data with mean centering and standard deviation scaling. Make sure column the mean/standard deviations are obtained from `train_df`. Create new data frames called `train_stand` and `test_stand`. Hint: use `preProcess()` from the `caret` package as in the notes.

10.  Verify the columns of `train_stand` have means of 0 and standard deviations of 1. What about `test_stand`?

11.  Compute the KNN train and test set accuracy with K=1 and K=20 for the standardized data.

12. Using cross-validation with 5 folds, pick the best value of K for KNN. Evaluate every value of K between 1 and 30. Plot the curve showing validation accuracy vs. K.  For the selected value of K, what is the training and test set accuracy?

    Make sure you use the seed in the code chunk shown below.

    ```{r}
    set.seed(393)
      
    # start writing your code here
    
    # k_values_to_try <-
    # training_control <- trainControl
    # knn_cv <- train
    ```

13. Pick any 3 variables and build a classification model that you train with cross-validation based on only these three variables from `train_stand`. What is the test set accuracy?