{
  "hash": "a9645063938db7f446b704541434e362",
  "result": {
    "markdown": "---\ntitle: \"Summarizing numerical associations\"\nsubtitle: \"Correllation and the least squares line\"\ndate: 02/15/23\nfrom: markdown+emoji\nimage: images/association.png\n---\n<!-- The bit before that is commented out adds publish date to document metadata and button links at the top of the doc. This workflow can be revisited but currently doesn't work because listings aren't updated with these dates, only the renderd docs. -->\n\n::: {.cell}\n\n:::\n\n\n\n[[Discuss]{.btn .btn-primary}](https://edstem.org/us/courses/31657) [[Reading Questions]{.btn .btn-primary}](https://www.gradescope.com/courses/477232) [[PDF]{.btn .btn-primary}](notes.pdf)\n\n\n\n\\\n\n[W]{.dropcap}hich of the following plots do you think depicts the relationship between the high school graduation rate and the poverty rate among the 50 US states?\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\npoverty <- read_delim(\"https://www.dropbox.com/s/0z45xgms0sie7l9/poverty.csv?dl=1\")\n\npoverty <- poverty %>%\n  mutate(group = case_when(\n    Poverty < 9 ~ \"low\",\n    Poverty >= 9 & Poverty <= 13 ~ \"med\",\n    Poverty > 13 ~ \"hi\"\n  )) \n\npA <- ggplot(poverty, aes(x = Poverty, \n                    y = Graduates)) +\n  geom_point() +\n  labs(x = \"Poverty Rate\",\n       y = \"Graduation Rate\") +\n  theme_bw()\n\nset.seed(50)\npoverty_shuffled <- poverty\npoverty_shuffled$Graduates <- sample(poverty$Graduates)\n\npB <- ggplot(poverty_shuffled, aes(x = Poverty, \n                    y = Graduates)) +\n  geom_point() +\n  labs(x = \"Poverty Rate\",\n       y = \"Graduation Rate\") +\n  theme_bw()\n\nlibrary(patchwork)\npA + pB\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=595.2}\n:::\n:::\n\n\nIf you guessed the plot on the left, you are correct :tada:.\n\nStates with higher poverty rates tend to have lower graduation rates. This is a prime example of two variables that are *associated*. In a previous set of notes we defined association between two categorical variables, but lets replace that with a more general definition that can apply here.\n\n**Association**\n:    There is an association between two variables if the conditional distribution of one varies as you move across values of the other.\n\nYou can detect associations in scatter plots by scanning from left to right along the x-axis and determining whether or not the conditional distribution of the y-variable is changing or not. In the figure to the left below, when you look first to the states with low poverty rates (in the blue box), you find that the conditional distribution of the graduation rate (represented by the blue density curve along the right side of the scatter plot) is high: most of those states have graduation rates between 85% and 90%. When you scan to the right in that scatter plot, and condition on having a high poverty rate (the states in the red box), the conditional distribution shifts downwards. Those states have graduations rates in the low 80%s.\n\n:::{.column-margin}\nThese density curves are conditional distribution because we've set a condition on the data we're visualizing. When focusing on the data that's in the blue box, for example, we've in effect set up a filter where Poverty < 9.\n:::\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Prepare plot on the left\npoverty_2 <- poverty %>%\n  filter(group != \"med\")\n\np_real_densities <-  poverty_2 %>%\n  ggplot(aes(y = Graduates, fill = group)) +\n  geom_density(alpha = .5) +\n  theme_void() + \n  theme(legend.position = \"none\") +\n  lims(y = c(77, 92.5))\n\np_real_scatter <- poverty %>%\n  ggplot(aes(x = Poverty, \n             y = Graduates)) +\n  annotate(\"rect\", xmin = 5, xmax = 9,\n           ymin = 77, ymax = 92.5, alpha = .35,\n           color = \"#00BFC4\", fill = NA) +\n  annotate(\"rect\", xmin = 13, xmax = 18,\n           ymin = 77, ymax = 92.5, alpha = .35,\n           color = \"#F8766D\", fill = NA) +\n  geom_point() +\n  geom_rug(data = poverty_2,\n           aes(color = group), \n           alpha = .8, sides = \"r\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\n# Prepare plot on the right\npoverty_shuffled_2 <- poverty_shuffled %>%\n  filter(group != \"med\")\n\np_shuf_densities <-  poverty_shuffled_2 %>%\n  ggplot(aes(y = Graduates, fill = group)) +\n  geom_density(alpha = .5) +\n  theme_void() + \n  theme(legend.position = \"none\") +\n  lims(y = c(77, 92.5))\n\np_shuf_scatter <- poverty_shuffled_2 %>%\n  ggplot(aes(x = Poverty, \n             y = Graduates)) +\n  annotate(\"rect\", xmin = 5, xmax = 9,\n           ymin = 77, ymax = 92.5, alpha = .35,\n           color = \"#00BFC4\", fill = NA) +\n  annotate(\"rect\", xmin = 13, xmax = 18,\n           ymin = 77, ymax = 92.5, alpha = .35,\n           color = \"#F8766D\", fill = NA) +\n  geom_point() +\n  geom_rug(data = poverty_shuffled_2,\n           aes(color = group), \n           alpha = .8, sides = \"r\") +\n  theme_bw() +\n  theme(legend.position = \"none\")\n\np_real_scatter + p_real_densities + \n  p_shuf_scatter + p_shuf_densities + \n  plot_layout(widths = c(4, 1, 4, 1))\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=720}\n:::\n:::\n\n\nThe plot on the right, by contrast, exhibits no association between poverty rate and graduation rate. When we compare the low poverty states with the high poverty states, their conditional distributions of Graduation rate are essentially the same.\n\nSo we can use the simple scatter plot to determine whether or not two numerical variables are associated, but sometimes a graphic isn't enough. In these notes we'll move from graphical summaries to numerical summaries and construct two different approaches to capturing these associations in numbers: the correlation coefficient and the simple linear model.\n\n## The Correlation Coefficient\n\nLet's set out to engineer our first numerical summary in the same manner that we have previously, by laying out the properties that we'd like our summary to have.\n\nPlease watch the following 12 minute video.\n\n[![](images/vid-thumbnail.png){width=400}](https://bcourses.berkeley.edu/courses/1521247/external_tools/78985)\n\n**Correlation coefficient, $r$**\n:    The correlation coefficient, $r$, between two variables $x$ and $y$ is\n     $$r = \\frac{1}{n-1}\\sum_{i=1}^n \\left( \\frac{x_i - \\bar{x}}{s_x} \\right) \\left( \\frac{y_i - \\bar{y}}{s_y} \\right)$$\n     \n:::{.column-margin}\nSeveral different statistics have been proposed for measuring association. This is the most common and is more specifically called the Pearson correlation.\n:::\n\n### Example: Poverty and Graduation rate\n\nThe data frame used to create the scatter plot above left looks like this.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nselect(poverty, Graduates, Poverty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 51 × 2\n   Graduates Poverty\n       <dbl>   <dbl>\n 1      79.9    14.6\n 2      90.6     8.3\n 3      83.8    13.3\n 4      80.9    18  \n 5      81.1    12.8\n 6      88.7     9.4\n 7      87.5     7.8\n 8      88.7     8.1\n 9      86      16.8\n10      84.7    12.1\n# … with 41 more rows\n```\n:::\n:::\n\n\nSince it is a data frame, we can use the `summarize()` function to calculate our summary statistic.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npoverty %>%\n  summarize(r = cor(Poverty, Graduates))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n       r\n   <dbl>\n1 -0.747\n```\n:::\n:::\n\n\nThe value of -0.747 tells us that the linear association between these variables is negative and reasonably strong. This is our first example of a *bivariate* summary statistic: there are two variables that we put inside the `cor()` function to compute our statistic.\n\nLet's repeat this calculation for the data frame that created the shapeless scatter plot with no association, `poverty_shuffled`.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npoverty_shuffled %>%\n  summarize(r = cor(Poverty, Graduates))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n        r\n    <dbl>\n1 -0.0546\n```\n:::\n:::\n\n\nAs expected, that scatter plot yields a correlation coefficient very close to zero because the points are scattered across all four quadrants of the plot.\n\n## The Simple Linear Model\n\nAnother approach to summarizing the linear association is to just ... draw a line.\n\n![](images/handdrawn-line.png){width=300 fig-align=\"center\"}\n\nThis line serves both a graphical summary and *also* as a numerical summary. After all, every line that you draw on a scatter plot is defined by two numbers: the slope and the y-intercept. This line is called a *simple linear model*.\n\n**Simple Linear Model**\n:    An expression for a possible value of the $y$ variable, $\\hat{y}$, as a linear function of the $x$ variable with slope $b_1$ and intercept $b_0.\n     $$\\hat{y} = b_0 + b_1x$$\n\nTherefore, a simple linear model captures the linear relationship of two variables in not one but *two* summary statistics, $b_0$ and $b_1$.\n\nFor the line above, we can do our best to eye-ball this. The line appears to rise -2 percentage points for every 2.5 that it runs, so I'd estimate the slope to be about $-2/2.5 = -0.8$. If I were to draw the line all the way to the left until it crossed the y-axis at a poverty rate of 0, its y-intercept would be around 95. So I could express the line that's drawn above as:\n\n$$\\hat{y} = 95 - 0.8 x$$\n\n### The Least Squares Line\n\nIf that felt a little shifty to you - drawing a line by hand and then eyeballing its slope and intercept - we can be more precise by using a more precisely-defined type of linear model: the least squares line. This is a method that we'll study in depth when we get to the unit on prediction, but for now, we'll use it because it makes calculation very easy. You can find the slope and intercept of the least squares line using statistics that we're already familiar with: $\\bar{x}, \\bar{y}, s_x, x_y$, and $r$. \n\n**Least Squares Slope**\n:    $$ b_1 = r \\frac{s_y}{s_x} $$\n\n**Least Squares Intercept**\n:    $$ b_0 = \\bar{y} - b_1 \\bar{x}$$\n\nSo how does this line look compared to the hand-drawn line? Let's find calculate the slope and intercept and add the line to our scatter plot.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nm1 <- lm(Graduates ~ Poverty, poverty)\n\nggplot(poverty, aes(x = Poverty, \n                    y = Graduates)) +\n  geom_point() +\n  geom_abline(slope = coef(m1)[2],\n              intercept = coef(m1)[1],\n              color = \"blue\") +\n  labs(x = \"Poverty Rate\",\n       y = \"Graduation Rate\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=288}\n:::\n:::\n\n\nThat works remarkably well!\n\nThe function that was used to calculate the least squares slope and intercept is `lm()`. \n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\nlm(Graduates ~ Poverty, data = poverty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = Graduates ~ Poverty, data = poverty)\n\nCoefficients:\n(Intercept)      Poverty  \n    96.2022      -0.8979  \n```\n:::\n:::\n\n\nThe syntax for `lm()` uses what's called \"formula notation\" in R. The first argument is a formula of the form `y ~ x` and can be read as, \"Explain the y as a function of the x\". In the second argument, you specify which data frame contains the variables used in the formula.\n\nSo if the correlation coefficient measures the strength of the linear relationship between two variables, what exactly are the slope and intercept measuring? The slope captures the expected change in the $y$ associated with the $x$ changing by 1 unit. In this example, states that are separated by 1 percentage point in their poverty rate tend to be separated by about -.89 in their graduation rate. This is distinct from what the correlation tells us because while $r$ will stay the same regardless of the units in which the data is measured, $b_1$ is expressly designed to tell us how those units of measurement relate to one another.\n\nWhat about the intercept? It tells us the value that we'd expect the $y$ to take when the $x$ takes a value of zero. Sometimes that's an informative statistics, sometime it is not. In this setting, do you really expect the graduation rate of rates to be around 96% when their poverty rate is zero? What would it even look like for a state to have a poverty rate of zero? The abstraction of the linear model allows us to ponder such a world, but the reality of economics in the US is that we would never actually observe poverty rates of zero.\n\nSo what good is the intercept? Well, it's useful in helping us calculate a residual.\n\n### Residuals\n\nOne of the benefits of explaining the association between two variables with a line instead of just the correlation coefficient is that it allows us to calculate what we would *expect* an observation's y-value to be if it behaved like a typical observation, so that we can see how far our expectation is from reality. That gap between expectation and reality is called a *residual*.\n\n**Residual** ($\\hat{e}_i$)\n:   The difference between the observed value of a data point, $y_i$, and the value that we would expect according to a linear model, $\\hat{y}_i$.\n    $$ \\hat{e}_i = y_i - \\hat{y}_i $$\n    \n:::{.column-margin}\n$\\hat{y}_i$ is said \"y hat sub i\" and is also called the \"fitted value\".\n:::\n    \nLet's calculate the residual for California. Here is that row in the data set.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\npoverty %>%\n  filter(State == \"California\") %>%\n  select(State, Graduates, Poverty)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  State      Graduates Poverty\n  <chr>          <dbl>   <dbl>\n1 California      81.1    12.8\n```\n:::\n:::\n\n\nThis shows us that $y_i = 81.1$, so the next step is to find where the line passes through California's x-value, $x_i = 12.8$. There are several ways to find that, including simply plugging that value into the equation for the line show above.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\ny_hat <- 96.2022 - 0.8979 * 12.8\ny_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 84.70908\n```\n:::\n:::\n\n\nWith that in hand, we can calculate California's residual.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n81.1 - y_hat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -3.60908\n```\n:::\n:::\n\n\nThis residual tells us that California is actually a bit of an underachiever. Among states with a poverty rate around 12.8, we would expect their graduate rate to be around 84.7. California's rate, however, is 81.1, a decrease of 3.6.\n\nThe calculation of the residual can be seen in the plot below.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggrepel)\npoverty <- poverty %>%\n  mutate(is_ca = case_when(\n    State == \"California\" ~ \"California (12.8, 81.1)\", \n    TRUE ~ \"\"))\nca_pred <- m1$fitted.values[poverty$State == \"California\"]\npoverty %>%\n  ggplot(aes(x = Poverty, \n             y = Graduates)) +\n  annotate(\"segment\", x = 12.8, xend = 12.8, \n           y = 81.1, yend = ca_pred,\n           lty = 2, color = \"tomato\") +\n  annotate(\"segment\", x = 5.2, xend = 12.8, \n           y = ca_pred, yend = ca_pred,\n           lty = 2, color = \"darkgray\") +\n  geom_point() +\n  geom_text_repel(aes(label = is_ca)) +\n  geom_abline(slope = coef(m1)[2],\n              intercept = coef(m1)[1],\n              color = \"blue\") +\n  labs(x = \"Poverty Rate\",\n       y = \"Graduation Rate\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](notes_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=384}\n:::\n:::\n\n\nThe horizontal dashed line represents $\\hat{y} = 84.7$, y-value of the least squares line when it passes through $x = 12.8$. The vertical red dashed line is the residual: the distance between the line and the observation in the y direction.\n\nResiduals open up a new avenue for numerical statistics. While the slope and intercept are two statistics that tell us about the *overall* linear relationship between the two variables, each residual is a statistic that tells us whether an *individual* observation's y-value is higher or lower than we'd expect based on its x-value.\n\n:::{.column-margin}\nIf you have $n$ data points, you can calculate $n$ residuals.\n:::\n\n## Summary\n\nIn these notes we considered the question of how to capture the association between two variables with numerical summary statistics. The correlation coefficient is one of the most common: it captures the strength and direction of the linear trend. This statistic can be used, along with other simple summary statistics, to calculate the slope and intercept of the least squares line. The least squares line is an alternative approach to summarizing the linear relationship between two numerical variables. It has the advantage of providing an expectation for the y-value of every observation, which allows us to calculate residuals, and expression of whether each observation is higher or lower than we'd expect.\n\nWe'll spend time practicing calculating these statistics - and looking at lots of scatter plots - in class tomorrow.\n",
    "supporting": [
      "notes_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}